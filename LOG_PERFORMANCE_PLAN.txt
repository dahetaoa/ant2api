LOG PERFORMANCE OPTIMIZATION PLAN - COMPREHENSIVE VERSION

OBJECTIVE
=========
When debug is disabled (DEBUG="" or DEBUG="off"), completely skip ALL log-related processing logic to reduce CPU and memory overhead to absolute minimum. Every piece of logging business code must be bypassed.

COMPLETE PERFORMANCE OVERHEAD ANALYSIS
======================================

1. OPENAI STREAM WRITER (internal/gateway/openai/stream.go)
-----------------------------------------------------------
Line 35: collectedEvents []map[string]any
   - Memory allocation for slice even when not needed

Line 192-210: writeSSEDataAndCollect()
   - Line 198: JSON unmarshal of already-marshaled data (DOUBLE SERIALIZATION!)
   - Line 199-200: Append to collectedEvents slice
   
Line 229-301: GetMergedResponse()
   - Lines 233-257: flushPending() closures and string builders
   - Lines 260-298: Full iteration over collectedEvents
   - TOTAL: O(n) processing of all events when logging disabled

2. CLAUDE SSE EMITTER (internal/gateway/claude/stream.go)
----------------------------------------------------------
Line 30: collectedEvents []map[string]any
   - Memory allocation for slice even when not needed

Line 321-339: writeSSE()
   - Line 322: JSON marshal (needed for SSE output)
   - Line 327-330: JSON unmarshal + append to collectedEvents (ONLY FOR LOGGING!)

Line 134-197: GetMergedResponse()
   - Lines 143-160: flushPending() closures and string builders
   - Lines 162-194: Full iteration over collectedEvents
   - TOTAL: O(n) processing of all events when logging disabled

3. VERTEX STREAM PARSER (internal/vertex/stream.go)
---------------------------------------------------
Line 69-70: rawChunks and mergedParts slices
   - Memory allocation even when not needed

Line 97-101: Raw chunk collection
   - Line 98: JSON unmarshal to rawChunk
   - Line 101: Append to rawChunks (ONLY FOR LOGGING!)

Line 124-134: Parts extraction for merging
   - Lines 124-131: Deep nesting access to extract parts
   - Line 129: Append to mergedParts (ONLY FOR LOGGING!)

Line 164: result.RawChunks = rawChunks
   - Assignment only used for logging

Line 166-179: MergedResponse building
   - Line 172: merge Parts() call (EXPENSIVE!)
   - Map creation and nesting (ONLY FOR LOGGING!)

4. GEMINI HANDLER (internal/gateway/gemini/handler.go)
------------------------------------------------------
Line 467: var mergedParts []any
   - Slice allocation even when not needed

Line 476-495: Extraction loop for merging
   - Line 477: JSON unmarshal rawChunk (ALREADY DONE UPSTREAM!)
   - Lines 478-494: Deep nesting to extract parts
   - Line 489: Append to mergedParts (ONLY FOR LOGGING!)

Lines 511-519: mergedResp building
   - Line 514: vertex.MergeParts() call (EXPENSIVE!)
   - Map creation (ONLY FOR LOGGING!)

5. HANDLER LAYER CALLS
----------------------
All three handlers call GetMergedResponse() UNCONDITIONALLY:
- openai/handler.go line 144: writer.GetMergedResponse()
- claude/handler.go line 122: emitter.GetMergedResponse()
- gemini/handler.go line 521-522: logger.BackendStreamResponse/ClientStreamResponse

IMPLEMENTATION PLAN
==================

STEP 1: Export log level check functions
----------------------------------------
File: internal/logger/logger.go
Location: After line 53

Add:
func IsClientLogEnabled() bool {
    return currentLogLevel >= LogLow
}

func IsBackendLogEnabled() bool {
    return currentLogLevel >= LogHigh
}

func IsAnyLogEnabled() bool {
    return currentLogLevel > LogOff
}

STEP 2: OpenAI StreamWriter - Conditional event collection
-----------------------------------------------------------
File: internal/gateway/openai/stream.go

2A. Modify writeSSEDataAndCollect (line 192-210):
func (sw *StreamWriter) writeSSEDataAndCollect(v any) error {
    b, err := jsonpkg.Marshal(v)
    if err != nil {
        return err
    }

    // ONLY collect events when client logging is enabled
    if logger.IsClientLogEnabled() {
        var event map[string]any
        if err := jsonpkg.Unmarshal(b, &event); err == nil {
            sw.collectedEvents = append(sw.collectedEvents, event)
        }
    }

    if _, err := fmt.Fprintf(sw.w, "data: %s\n\n", b); err != nil {
        return err
    }
    if f, ok := sw.w.(http.Flusher); ok {
        f.Flush()
    }
    return nil
}

2B. Modify GetMergedResponse (line 229):
func (sw *StreamWriter) GetMergedResponse() []any {
    if !logger.IsClientLogEnabled() {
        return nil
    }
    sw.mu.Lock()
    defer sw.mu.Unlock()
    // ... rest unchanged
}

2C. Add import for logger package at top of file

STEP 3: Claude SSEEmitter - Conditional event collection
---------------------------------------------------------
File: internal/gateway/claude/stream.go

3A. Modify writeSSE (line 321-339):
func (e *SSEEmitter) writeSSE(event string, data any) error {
    b, err := jsonpkg.Marshal(data)
    if err != nil {
        return err
    }

    // ONLY collect events when client logging is enabled
    if logger.IsClientLogEnabled() {
        var eventData map[string]any
        if err := jsonpkg.Unmarshal(b, &eventData); err == nil {
            e.collectedEvents = append(e.collectedEvents, eventData)
        }
    }

    if _, err := fmt.Fprintf(e.w, "event: %s\ndata: %s\n\n", event, b); err != nil {
        return err
    }
    if f, ok := e.w.(http.Flusher); ok {
        f.Flush()
    }
    return nil
}

3B. Modify GetMergedResponse (line 134):
func (e *SSEEmitter) GetMergedResponse() []any {
    if !logger.IsClientLogEnabled() {
        return nil
    }
    e.mu.Lock()
    defer e.mu.Unlock()
    // ... rest unchanged
}

3C. Add import for logger package at top of file

STEP 4: Vertex Stream Parser - Conditional merge building
----------------------------------------------------------
File: internal/vertex/stream.go

4A. At the start of ParseStreamWithResult (after line 65):
buildMerged := logger.IsBackendLogEnabled()

var rawChunks []map[string]any
var mergedParts []any
// Remove unconditional slice declarations, only declare when needed

4B. Modify rawChunk collection (line 97-101):
Replace:
var rawChunk map[string]any
if err := jsonpkg.UnmarshalString(jsonData, &rawChunk); err != nil {
    continue
}
rawChunks = append(rawChunks, rawChunk)

With:
var rawChunk map[string]any
if buildMerged {
    if err := jsonpkg.UnmarshalString(jsonData, &rawChunk); err != nil {
        // Continue to parse into data anyway
    } else {
        rawChunks = append(rawChunks, rawChunk)
    }
}

4C. Modify mergedParts extraction (line 124-134):
Wrap entire block:
if buildMerged {
    if respMap, ok := rawChunk["response"].(map[string]any); ok {
        if candidates, ok := respMap["candidates"].([]any); ok && len(candidates) > 0 {
            if cand, ok := candidates[0].(map[string]any); ok {
                if content, ok := cand["content"].(map[string]any); ok {
                    if parts, ok := content["parts"].([]any); ok {
                        mergedParts = append(mergedParts, parts...)
                    }
                }
            }
        }
    }
}

4D. Modify result building (line 164-179):
Replace:
result.RawChunks = rawChunks
result.MergedResponse = map[string]any{...}

With:
if buildMerged {
    result.RawChunks = rawChunks
    result.MergedResponse = map[string]any{
        "response": map[string]any{
            "candidates": []any{
                map[string]any{
                    "content": map[string]any{
                        "role":  "model",
                        "parts": mergeParts(mergedParts),
                    },
                    "finishReason": lastFinishReason,
                },
            },
            "usageMetadata": lastUsage,
        },
    }
}

4E. Add import for logger package at top of file

STEP 5: Gemini Handler - Conditional merge building
----------------------------------------------------
File: internal/gateway/gemini/handler.go

5A. At line 467, conditionally declare:
buildMerged := logger.IsBackendLogEnabled()
var mergedParts []any
// Only needed when buildMerged is true

5B. Wrap parts extraction (lines 476-495):
Replace lines 476-495 with:
if jsonData != "[DONE]" && jsonData != "" {
    if buildMerged {
        var rawChunk map[string]any
        if jsonpkg.UnmarshalString(jsonData, &rawChunk) == nil {
            if respMap, ok := rawChunk["response"].(map[string]any); ok {
                if usage, ok := respMap["usageMetadata"]; ok {
                    lastUsage = usage
                }
                if candidates, ok := respMap["candidates"].([]any); ok && len(candidates) > 0 {
                    if cand, ok := candidates[0].(map[string]any); ok {
                        if fr, ok := cand["finishReason"].(string); ok && fr != "" {
                            lastFinishReason = fr
                        }
                        if content, ok := cand["content"].(map[string]any); ok {
                            if parts, ok := content["parts"].([]any); ok {
                                mergedParts = append(mergedParts, parts...)
                            }
                        }
                    }
                }
            }
        }
    }
    // ... rest of stream forwarding unchanged
}

NOTE: The above may break if lastUsage/lastFinishReason are needed elsewhere.
Check if they are only used for logging. If so, wrap them too.

5C. Modify mergedResp and logger calls (lines 511-522):
Replace:
mergedResp := map[string]any{...}
logger.BackendStreamResponse(http.StatusOK, duration, mergedResp)
logger.ClientStreamResponse(http.StatusOK, duration, mergedResp)

With:
if buildMerged {
    mergedResp := map[string]any{
        "response": map[string]any{
            "candidates": []any{map[string]any{
                "content":      map[string]any{"role": "model", "parts": vertex.MergeParts(mergedParts)},
                "finishReason": lastFinishReason,
            }},
            "usageMetadata": lastUsage,
        },
    }
    logger.BackendStreamResponse(http.StatusOK, duration, mergedResp)
    logger.ClientStreamResponse(http.StatusOK, duration, mergedResp)
}

STEP 6: Handler layer - Conditional logger calls
-------------------------------------------------

6A. OpenAI handler (internal/gateway/openai/handler.go lines 143-144):
Replace:
logger.BackendStreamResponse(http.StatusOK, duration, streamResult.MergedResponse)
logger.ClientStreamResponse(http.StatusOK, duration, writer.GetMergedResponse())

With:
if logger.IsBackendLogEnabled() {
    logger.BackendStreamResponse(http.StatusOK, duration, streamResult.MergedResponse)
}
if logger.IsClientLogEnabled() {
    logger.ClientStreamResponse(http.StatusOK, duration, writer.GetMergedResponse())
}

6B. Claude handler (internal/gateway/claude/handler.go lines 121-122):
Replace:
logger.BackendStreamResponse(http.StatusOK, duration, streamResult.MergedResponse)
logger.ClientStreamResponse(http.StatusOK, duration, emitter.GetMergedResponse())

With:
if logger.IsBackendLogEnabled() {
    logger.BackendStreamResponse(http.StatusOK, duration, streamResult.MergedResponse)
}
if logger.IsClientLogEnabled() {
    logger.ClientStreamResponse(http.StatusOK, duration, emitter.GetMergedResponse())
}

6C. Gemini handler: Already handled in Step 5C

STEP 7: Non-streaming log calls optimization
--------------------------------------------
Check all non-streaming log calls and wrap with conditionals:

Pattern:
if logger.IsClientLogEnabled() {
    logger.ClientResponse(...)
}

This applies to:
- openai/handler.go lines 23, 33, 59, 104, 110
- claude/handler.go lines 57, 63, 84
- gemini/handler.go lines 240, 254, 275, 370, 376

For ClientRequest calls:
if logger.IsClientLogEnabled() {
    logger.ClientRequest(...)
    logger.ClientRequestWithHeaders(...)
}

STEP 8: Optimize logger functions to not call sanitizer when disabled
----------------------------------------------------------------------
File: internal/logger/logger.go

The sanitizeJSONForLog function is expensive. Ensure it's never called when logging is disabled.

Current functions that call sanitizer:
- printJSON (line 250-258)
- formatRawJSON (line 260-272)

These are only called inside logged functions that already check level, so no change needed.
But add early returns for safety:

func printJSON(v any) {
    if currentLogLevel == LogOff {
        return
    }
    // ... rest
}

func formatRawJSON(rawJSON []byte) string {
    if currentLogLevel == LogOff {
        return ""
    }
    // ... rest
}

PERFORMANCE IMPACT SUMMARY
==========================
When DEBUG=off (LogOff):

ELIMINATED OPERATIONS:
1. JSON unmarshaling of every SSE chunk for event collection (3 endpoints)
2. Appending to collectedEvents slice (OpenAI, Claude)
3. Appending to rawChunks and mergedParts slices (Vertex, Gemini)
4. GetMergedResponse() processing - full iteration over collected events
5. mergeParts() recursive processing
6. MergedResponse map construction
7. sanitizeJSONForLog recursive processing

MEMORY SAVED:
- collectedEvents slice in StreamWriter
- collectedEvents slice in SSEEmitter  
- rawChunks slice in StreamResult
- mergedParts slice accumulation
- All intermediate map[string]any allocations

CPU SAVED:
- O(n) JSON unmarshal per chunk eliminated
- O(n) event iteration in GetMergedResponse eliminated
- Recursive mergeParts processing eliminated
- Recursive sanitizeJSONForLog processing eliminated

TESTING GUIDANCE
================
1. Build: go build ./...

2. DEBUG=high: Verify all logs appear correctly

3. DEBUG=low: Verify client logs appear, backend logs do not

4. DEBUG=off or DEBUG="": Verify:
   - No logs appear
   - Streaming works correctly
   - No performance overhead (verify with benchmark if possible)
   - Memory usage is lower

5. Test all three endpoints in all debug modes:
   - OpenAI streaming and non-streaming
   - Claude streaming and non-streaming
   - Gemini streaming and non-streaming

DO NOT
======
- Do NOT break streaming functionality
- Do NOT change log output when logging IS enabled
- Do NOT remove any functionality
- Do NOT modify actual request/response processing
- Do NOT change signature handling logic
- Do NOT change image processing logic
